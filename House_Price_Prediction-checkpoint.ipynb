{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457408eb-6ca6-4b1c-b657-7612a2e44783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston house price prediction\n",
    "The problem that we are going to solve here is that given a set of features that describe a house in Boston, our machine learning model must predict the house price. To train our machine learning model with boston housing data, we will be using scikit-learn‚Äôs boston dataset.\n",
    "\n",
    "In this dataset, each row describes a boston town or suburb. There are 506 rows and 13 attributes (features) with a target column (price).\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names\n",
    "# Importing the libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "# Importing the Boston Housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "# Initializing the dataframe\n",
    "data = pd.DataFrame(boston.data)\n",
    "# See head of the dataset\n",
    "data.head()\n",
    "#Adding the feature names to the dataframe\n",
    "data.columns = boston.feature_names\n",
    "data.head()\n",
    "CRIM per capita crime rate by town <br>\n",
    "ZN proportion of residential land zoned for lots over 25,000 sq.ft. <br>\n",
    "INDUS proportion of non-retail business acres per town <br>\n",
    "CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) <br>\n",
    "NOX nitric oxides concentration (parts per 10 million) <br>\n",
    "RM average number of rooms per dwelling <br>\n",
    "AGE proportion of owner-occupied units built prior to 1940 <br>\n",
    "DIS weighted distances to five Boston employment centres <br>\n",
    "RAD index of accessibility to radial highways <br>\n",
    "TAX full-value property-tax rate per 10,000usd <br>\n",
    "PTRATIO pupil-teacher ratio by town <br>\n",
    "B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town <br>\n",
    "LSTAT % lower status of the population <br>\n",
    "Each record in the database describes a Boston suburb or town.\n",
    "#Adding target variable to dataframe\n",
    "data['PRICE'] = boston.target \n",
    "# Median value of owner-occupied homes in $1000s\n",
    "#Check the shape of dataframe\n",
    "data.shape\n",
    "data.columns\n",
    "data.dtypes\n",
    "# Identifying the unique number of values in the dataset\n",
    "data.nunique()\n",
    "# Check for missing values\n",
    "data.isnull().sum()\n",
    "# See rows with missing values\n",
    "data[data.isnull().any(axis=1)]\n",
    "# Viewing the data statistics\n",
    "data.describe()\n",
    "# Finding out the correlation between the features\n",
    "corr = data.corr()\n",
    "corr.shape\n",
    "# Plotting the heatmap of correlation between features\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(corr, cbar=True, square= True, fmt='.1f', annot=True, annot_kws={'size':15}, cmap='Greens')\n",
    "# Spliting target variable and independent variables\n",
    "X = data.drop(['PRICE'], axis = 1)\n",
    "y = data['PRICE']\n",
    "# Splitting to training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 4)\n",
    "# Linear regression\n",
    "#### Training the model\n",
    "# Import library for Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a Linear regressor\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets \n",
    "lm.fit(X_train, y_train)\n",
    "# Value of y intercept\n",
    "lm.intercept_\n",
    "#Converting the coefficient values to a dataframe\n",
    "coeffcients = pd.DataFrame([X_train.columns,lm.coef_]).T\n",
    "coeffcients = coeffcients.rename(columns={0: 'Attribute', 1: 'Coefficients'})\n",
    "coeffcients\n",
    "#### Model Evaluation\n",
    "# Model prediction on train data\n",
    "y_pred = lm.predict(X_train)\n",
    "# Model Evaluation\n",
    "print('R^2:',metrics.r2_score(y_train, y_pred))\n",
    "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_train, y_pred))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1))\n",
    "print('MAE:',metrics.mean_absolute_error(y_train, y_pred))\n",
    "print('MSE:',metrics.mean_squared_error(y_train, y_pred))\n",
    "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_train, y_pred)))\n",
    "ùëÖ^2 : It is a measure of the linear relationship between X and Y. It is interpreted as the proportion of the variance in the dependent variable that is predictable from the independent variable.\n",
    "\n",
    "Adjusted ùëÖ^2 :The adjusted R-squared compares the explanatory power of regression models that contain different numbers of predictors.\n",
    "\n",
    "MAE : It is the mean of the absolute value of the errors. It measures the difference between two continuous variables, here actual and predicted values of y.¬†\n",
    "\n",
    "MSE: The¬†mean square error¬†(MSE) is just like the MAE, but¬†squares¬†the difference before summing them all instead of using the absolute value.¬†\n",
    "\n",
    "RMSE: The¬†mean square error¬†(MSE) is just like the MAE, but¬†squares¬†the difference before summing them all instead of using the absolute value.¬†\n",
    "\n",
    "# Checking Normality of errors\n",
    "sns.distplot(y_train-y_pred)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "Here the residuals are normally distributed. So normality assumption is satisfied\n",
    "#### For test data\n",
    "# Predicting Test data with the model\n",
    "y_test_pred = lm.predict(X_test)\n",
    "# Model Evaluation\n",
    "acc_linreg = metrics.r2_score(y_test, y_test_pred)\n",
    "print('R^2:', acc_linreg)\n",
    "print('Adjusted R^2:',1 - (1-metrics.r2_score(y_test, y_test_pred))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1))\n",
    "print('MAE:',metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "print('MSE:',metrics.mean_squared_error(y_test, y_test_pred))\n",
    "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "Here the model evaluations scores are almost matching with that of train data. So the model is not overfitting.\n",
    "\n",
    "# Evaluation and comparision of all the models\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Linear Regression'],\n",
    "    'R-squared Score': [acc_linreg*100]})\n",
    "models.sort_values(by='R-squared Score', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
